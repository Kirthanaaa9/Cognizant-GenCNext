
Big O notation is employed to specify how the time or space consumed by an algorithm increases with the growth in the input size. Big O assists in understanding algorithm efficiency without being concerned with the specific hardware or environment. Big O only concentrates on the most significant portion of the running time when the input becomes large. Big O aids in algorithm comparison based on scaling.
Example:
O(1): The time remains constant regardless of the size of the input.
O(n): The time grows linearly with input size.
O(log n): The time grows slowly even as input size increases greatly, such as in binary search.

Best, Average, and Worst Case for Search Operations
When analyzing algorithms such as search, we typically refer to:
 Best case: The best possible scenario.
 Average case: A general or average case.
 Worst case: The worst possible scenario in which the algorithm works the slowest.

Linear Search:
 Best case: O(1) → The item is in the first position.
 Average case: O(n) → The item is in the middle or randomly distributed.
 Worst case: O(n) → The item is at the last position or does not exist.

Binary Search:
 Best case: O(1) → The item is at middle index in the first iteration.
 Average case: O(log n) → The item is somewhere in the sorted list but requires a couple of comparisons.
 Worst case: O(log n) → The item is either not there or at an end of the search range.

Summary: Big O can be used to estimate how quickly or slowly an algorithm will execute as inputs increase. Binary search (O(log n)) is quicker than linear search (O(n)) when data is sorted in searching.
